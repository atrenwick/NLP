{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66b27b4",
   "metadata": {},
   "source": [
    "#  HOPS\n",
    "No, not the hops you nmake beer from.\n",
    "HOPS is really good at parsing French, both Old French and Modern French : you can get HOPS here : https://github.com/hopsparser/hopsparser\n",
    "\n",
    "First, you'll have to intall it: feed this to your console\n",
    "'pip install hopsparser'\n",
    "\n",
    "That gets you the code you need. You'll also need models : you can get info and links to them here :\n",
    "https://github.com/hopsparser/hopsparser/blob/main/docs/models.md\n",
    "\n",
    "My reccommedation : give each model a 3 digit code number, and put it in a folder with that name. That makes paths a lot simpler, and makes things simpler for you too : model 241 is a lot easier to remember than the specific combination of treebank and BERT-like element, and a whole lot easier if you're going to use multiple models to find which one suits your particular use case\n",
    "\n",
    "HOPS can run as a component in Spacy, as a server, or in the command line. Since the developer already has docs on how to do the first two (https://hopsparser.readthedocs.io/en/stable/index.html), we'll look at the last one : running HOPS in your command line, with Python to help out too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f7727a",
   "metadata": {},
   "source": [
    "1. Import the libraries we'll need : urllib for downloading, pandas for creating a dataframe, tarfile for decompressing and os to interact with the system\n",
    "that we'll use to download and name the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942f2829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request \n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the URL we want to download\n",
    "url = 'https://zenodo.org/record/7703346/files/UD_French-FTB-flaubert.tar.xz?download=1'\n",
    "\n",
    "# specify the path to where we want to save the model, followed by the user-friendly code, keeping the extensions from the URL\n",
    "save_path = '/Volumes/Data/'\n",
    "code = '241'\n",
    "extensions = '.tar.xz'\n",
    "file_name = save_path + code + extensions\n",
    "model_specs = url[40:-18]\n",
    "   \n",
    "# keep a record of what code we assigned to which model, and keep that off to one side for the moment\n",
    "model_codes = pd.DataFrame([{'url':url,'code':code}])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3ad982",
   "metadata": {},
   "source": [
    "Download the model to where we specified with the name specified (well, it'll appear there once it's done downloadingâ€¦)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a91337",
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(model_link) as response, open(file_name, 'wb') as out_file:\n",
    "    data = response.read() \n",
    "    out_file.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1769465",
   "metadata": {},
   "source": [
    "The model we just downloaded is compressed, so we need to uncompress it. \n",
    "There'll be 3 things in the folder : a file called config.json, a file called weights.pt and another folder, called 'lexers'.\n",
    "\n",
    "The slash specifies that we want the content extracted to the top level of the filename we provided\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20224bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(file_name) as f:\n",
    "    f.extractall('/' + code)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f858d242",
   "metadata": {},
   "source": [
    "HOPS runs in the command line, and we need 4 elements to make a valid command:\n",
    "- A 'noun + verb combination' : this is easy : we need to tell the command line which app to use : 'hopsparser' and what we want to do : 'parse'. We'll store these as 'hops_verb' to take care of spaces they need between and after\n",
    "- Model : path to the folder containing the model we want to use\n",
    "- Input file :\n",
    "- Output file : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "506e71c7",
   "metadata": {},
   "outputs": [
   ],
   "source": [
    "hops_verb = 'hopsparser parse '\n",
    "model_path = file_name.replace('241.tar.xz','241/')\n",
    "input_file = '/Volumes/Data/sample_text.txt'\n",
    "output_file = '/Volumes/Data/sample_text-241.txt'\n",
    "model_specs = url[40:-18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368fac2",
   "metadata": {},
   "source": [
    "We need to add a level of quotes, otherwise Python will try and execute the command rather than sending the command to os.system \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba52039b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hopsparser parse /Volumes/AlphaThree/241/UD_French-FTB-flaubert /Volumes/AlphaThree/sample_text.txt /Volumes/AlphaThree/sample_text-241.txt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hops_command = \"\\'\" + hops_verb + model_path + model_specs + \" \" + input_file + \" \" + output_file + \"\\'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b11a300",
   "metadata": {},
   "source": [
    "If there's only one file to tag, you're not going to save much time making a function to glue these parts together for the different files, nor making another function that stores those commands before sending them to the command line, but you've got lots of texts, long texts, or lots of models to evaluate, now's the palce to do it. \n",
    "\n",
    "If the latter is the case and you're running on CPU rather than GPU, you'll probably be able to run several virtual environments simultaneously to tag several texts in parallel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a0a3a25",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hops_command' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m os\u001b[38;5;241m.\u001b[39msystem(\u001b[43mhops_command\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hops_command' is not defined"
     ]
    }
   ],
   "source": [
    "os.system(hops_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "517cd6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOPS will tag away and create the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a660a1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'conda activate /Users/Adam/top/anaconda3/envs/newhops ; hopsparser parse /Volumes/AlphaThree/241/UD_French-FTB-flaubert /Volumes/AlphaThree/sample_text.txt /Volumes/AlphaThree/sample_text-241.txt'\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
